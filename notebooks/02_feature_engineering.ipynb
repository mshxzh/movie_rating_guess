{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T19:42:09.410287Z",
     "start_time": "2025-12-29T19:42:09.239190Z"
    },
    "execution": {
     "iopub.execute_input": "2025-12-30T20:27:45.344686Z",
     "iopub.status.busy": "2025-12-30T20:27:45.344396Z",
     "iopub.status.idle": "2025-12-30T20:27:47.046699Z",
     "shell.execute_reply": "2025-12-30T20:27:47.046410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/01 20:55:25 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/01 20:55:25 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/01 20:55:25 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/01 20:55:25 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/01 20:55:25 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/01 20:55:25 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ MLflow experiment set: movie-rating-feature-engineering +++\n",
      "\n",
      "Dataset shape: (9726, 9)\n",
      "vote_average dtype: float64\n",
      "\n",
      "Training set size: 7780\n",
      "Test set size: 1946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>original_language</th>\n",
       "      <th>genre</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>1986-07-30</td>\n",
       "      <td>Flight of the Navigator</td>\n",
       "      <td>12-year-old David is accidentally knocked out ...</td>\n",
       "      <td>20.522</td>\n",
       "      <td>618</td>\n",
       "      <td>en</td>\n",
       "      <td>Family, Science Fiction, Adventure</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/dS4jmRcEAm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>Farewell My Concubine</td>\n",
       "      <td>Abandoned by his prostitute mother in 1920, Do...</td>\n",
       "      <td>19.009</td>\n",
       "      <td>353</td>\n",
       "      <td>zh</td>\n",
       "      <td>Drama</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/f54hNIiHNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>Justice League vs. Teen Titans</td>\n",
       "      <td>Robin is sent by Batman to work with the Teen ...</td>\n",
       "      <td>48.531</td>\n",
       "      <td>684</td>\n",
       "      <td>en</td>\n",
       "      <td>Science Fiction, Action, Animation</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/3G6RPpafXA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2009-09-29</td>\n",
       "      <td>Superman/Batman: Public Enemies</td>\n",
       "      <td>United States President Lex Luthor uses the on...</td>\n",
       "      <td>38.864</td>\n",
       "      <td>476</td>\n",
       "      <td>en</td>\n",
       "      <td>Science Fiction, Animation, Action, Adventure,...</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/izvMc22ywS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>1967-12-20</td>\n",
       "      <td>Asterix the Gaul</td>\n",
       "      <td>In the year 50 BC, Gaul is occupied by the Rom...</td>\n",
       "      <td>17.614</td>\n",
       "      <td>536</td>\n",
       "      <td>fr</td>\n",
       "      <td>Family, Animation, Adventure, Comedy</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/jBDZ68iRPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     release_date                            title  \\\n",
       "5144   1986-07-30          Flight of the Navigator   \n",
       "5780   1993-01-01            Farewell My Concubine   \n",
       "1589   2016-05-13   Justice League vs. Teen Titans   \n",
       "2146   2009-09-29  Superman/Batman: Public Enemies   \n",
       "6482   1967-12-20                 Asterix the Gaul   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "5144  12-year-old David is accidentally knocked out ...      20.522   \n",
       "5780  Abandoned by his prostitute mother in 1920, Do...      19.009   \n",
       "1589  Robin is sent by Batman to work with the Teen ...      48.531   \n",
       "2146  United States President Lex Luthor uses the on...      38.864   \n",
       "6482  In the year 50 BC, Gaul is occupied by the Rom...      17.614   \n",
       "\n",
       "     vote_count original_language  \\\n",
       "5144        618                en   \n",
       "5780        353                zh   \n",
       "1589        684                en   \n",
       "2146        476                en   \n",
       "6482        536                fr   \n",
       "\n",
       "                                                  genre  \\\n",
       "5144                 Family, Science Fiction, Adventure   \n",
       "5780                                              Drama   \n",
       "1589                 Science Fiction, Action, Animation   \n",
       "2146  Science Fiction, Animation, Action, Adventure,...   \n",
       "6482               Family, Animation, Adventure, Comedy   \n",
       "\n",
       "                                             poster_url  \n",
       "5144  https://image.tmdb.org/t/p/original/dS4jmRcEAm...  \n",
       "5780  https://image.tmdb.org/t/p/original/f54hNIiHNI...  \n",
       "1589  https://image.tmdb.org/t/p/original/3G6RPpafXA...  \n",
       "2146  https://image.tmdb.org/t/p/original/izvMc22ywS...  \n",
       "6482  https://image.tmdb.org/t/p/original/jBDZ68iRPE...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MLflow imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "\n",
    "# Set environment variable to avoid tokenizer parallelism\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"movie-rating-feature-engineering\")\n",
    "print(\"+++ MLflow experiment set: movie-rating-feature-engineering +++\")\n",
    "\n",
    "# Load data\n",
    "data_path = Path(\"../data/raw/movies.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "df['vote_average'] = pd.to_numeric(df['vote_average'], errors='coerce')\n",
    "df = df[~df.vote_average.isna()]\n",
    "df = df[df['vote_average'] != 0]\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"vote_average dtype: {df['vote_average'].dtype}\")\n",
    "\n",
    "# Split data into X and y BEFORE pipeline transformation\n",
    "X = df.drop('vote_average', axis=1)\n",
    "y = df['vote_average']\n",
    "\n",
    "# Train/test split\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test and train data\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T19:42:10.660206Z",
     "start_time": "2025-12-29T19:42:10.636211Z"
    },
    "execution": {
     "iopub.execute_input": "2025-12-30T20:27:47.072641Z",
     "iopub.status.busy": "2025-12-30T20:27:47.072442Z",
     "iopub.status.idle": "2025-12-30T20:27:47.086145Z",
     "shell.execute_reply": "2025-12-30T20:27:47.085816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom transformers imported from src.transformers\n"
     ]
    }
   ],
   "source": [
    "# Import custom transformers from src module\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import from src\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import all custom transformers\n",
    "from src.transformers import (\n",
    "    ColumnSelector,\n",
    "    DataTypeFixer,\n",
    "    YearBinning,\n",
    "    GenreMultiLabelEncoder,\n",
    "    LanguageGrouper,\n",
    "    LightweightTextEmbedder,\n",
    "    SelectiveStandardScaler,\n",
    "    CategoricalOneHotEncoder,\n",
    "    SentenceTransformerEmbedder,\n",
    ")\n",
    "\n",
    "print(\"Custom transformers imported from src.transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Feature Engineering Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline configurations\n",
    "columns_to_keep = ['release_date', 'title', 'overview', 'original_language', 'genre']\n",
    "\n",
    "# Hyperparameters\n",
    "LANGUAGE_THRESHOLD = 0.01\n",
    "OVERVIEW_MAX_FEATURES = 50\n",
    "TITLE_MAX_FEATURES = 30\n",
    "\n",
    "def build_pipeline_v1_original():\n",
    "    \"\"\"Version 1: Original - TF-IDF + OneHotEncoder\"\"\"\n",
    "    return Pipeline([\n",
    "        ('select_columns', ColumnSelector(columns=columns_to_keep)),\n",
    "        ('fix_dtypes', DataTypeFixer()),\n",
    "        ('bin_years', YearBinning()),\n",
    "        ('encode_genres', GenreMultiLabelEncoder()),\n",
    "        ('group_languages', LanguageGrouper(threshold=LANGUAGE_THRESHOLD)),\n",
    "        ('embed_overview', LightweightTextEmbedder(column='overview', max_features=OVERVIEW_MAX_FEATURES, prefix='overview')),\n",
    "        ('embed_title', LightweightTextEmbedder(column='title', max_features=TITLE_MAX_FEATURES, prefix='title')),\n",
    "        ('onehot_encode', CategoricalOneHotEncoder(columns=['year_bin', 'original_language'])),\n",
    "        ('scale_features', SelectiveStandardScaler()),\n",
    "    ])\n",
    "\n",
    "def build_pipeline_v2_sentence_transformers():\n",
    "    \"\"\"Version 2: Sentence Transformers - Lightweight embeddings for Lambda\"\"\"\n",
    "    return Pipeline([\n",
    "        ('select_columns', ColumnSelector(columns=columns_to_keep)),\n",
    "        ('fix_dtypes', DataTypeFixer()),\n",
    "        ('bin_years', YearBinning()),\n",
    "        ('encode_genres', GenreMultiLabelEncoder()),\n",
    "        ('group_languages', LanguageGrouper(threshold=LANGUAGE_THRESHOLD)),\n",
    "        # Use sentence transformers instead of TF-IDF\n",
    "        ('embed_overview', SentenceTransformerEmbedder(column='overview', model_name='all-MiniLM-L6-v2', prefix='overview')),\n",
    "        ('embed_title', SentenceTransformerEmbedder(column='title', model_name='all-MiniLM-L6-v2', prefix='title')),\n",
    "        ('onehot_encode', CategoricalOneHotEncoder(columns=['year_bin', 'original_language'])),\n",
    "        ('scale_features', SelectiveStandardScaler()),\n",
    "    ])\n",
    "\n",
    "# Dictionary of all pipeline versions\n",
    "PIPELINE_VERSIONS = {\n",
    "    'v1_original': {\n",
    "        'name': 'Original (TF-IDF + OneHot)',\n",
    "        'builder': build_pipeline_v1_original,\n",
    "        'description': 'Baseline: TF-IDF text features with OneHotEncoder for categoricals'\n",
    "    },\n",
    "    'v2_sentence_transformer': {\n",
    "        'name': 'Sentence Transformers (Lambda-ready)',\n",
    "        'builder': build_pipeline_v2_sentence_transformers,\n",
    "        'description': 'Lightweight sentence embeddings (384 dim), suitable for Lambda deployment',\n",
    "        'requires': 'sentence-transformers'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover available pipeline versions\n",
    "models_dir = Path('../models')\n",
    "pipeline_files = list(models_dir.glob('feature_pipeline_*.pkl'))\n",
    "\n",
    "AVAILABLE_PIPELINES = {}\n",
    "for pipeline_file in pipeline_files:\n",
    "    version_key = pipeline_file.stem.replace('feature_pipeline_', '')\n",
    "    AVAILABLE_PIPELINES[version_key] = {\n",
    "        'path': pipeline_file,\n",
    "        'name': version_key.replace('_', ' ').title()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All Pipeline Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_log_pipeline(version_key, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fit a pipeline version and log to MLflow\"\"\"\n",
    "    \n",
    "    config = PIPELINE_VERSIONS[version_key]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"PIPELINE: {config['name']}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Description: {config['description']}\")\n",
    "    \n",
    "    # Build pipeline\n",
    "    pipeline = config['builder']()\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"{version_key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"pipeline_version\", version_key)\n",
    "        mlflow.log_param(\"version_name\", config['name'])\n",
    "        mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "        mlflow.log_param(\"test_size\", TEST_SIZE)\n",
    "        mlflow.log_param(\"language_threshold\", LANGUAGE_THRESHOLD)\n",
    "        \n",
    "        # Log text feature config\n",
    "        has_tfidf = 'TF-IDF' in config['name']\n",
    "        has_sentence_transformer = 'Sentence' in config['name']\n",
    "        has_onehot = 'No OneHot' not in config['name']\n",
    "        \n",
    "        mlflow.log_param(\"text_embedding_type\", \n",
    "                        'sentence_transformer' if has_sentence_transformer else 'tfidf')\n",
    "        mlflow.log_param(\"uses_onehot_encoder\", has_onehot)\n",
    "        \n",
    "        if has_tfidf:\n",
    "            mlflow.log_param(\"overview_max_features\", OVERVIEW_MAX_FEATURES)\n",
    "            mlflow.log_param(\"title_max_features\", TITLE_MAX_FEATURES)\n",
    "        \n",
    "        print(\"\\nMLflow tracking enabled\")\n",
    "        print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n",
    "        \n",
    "        # Fit pipeline\n",
    "        print(\"\\nFitting pipeline...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            X_train_transformed = pipeline.fit_transform(X_train)\n",
    "            fit_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"Pipeline fitted in {fit_time:.2f}s\")\n",
    "            print(f\"Features: {X_train.shape[1]} → {X_train_transformed.shape[1]}\")\n",
    "            \n",
    "            # Transform test data\n",
    "            print(\"\\nTransforming test data...\")\n",
    "            transform_start = time.time()\n",
    "            X_test_transformed = pipeline.transform(X_test)\n",
    "            transform_time = time.time() - transform_start\n",
    "            \n",
    "            print(f\"Test data transformed in {transform_time:.2f}s\")\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_param(\"input_features\", X_train.shape[1])\n",
    "            mlflow.log_param(\"output_features\", X_train_transformed.shape[1])\n",
    "            mlflow.log_metric(\"fit_time_seconds\", fit_time)\n",
    "            mlflow.log_metric(\"transform_time_seconds\", transform_time)\n",
    "            mlflow.log_metric(\"feature_expansion_ratio\", \n",
    "                            X_train_transformed.shape[1] / X_train.shape[1])\n",
    "            mlflow.log_metric(\"total_samples\", len(X_train) + len(X_test))\n",
    "            \n",
    "            # Log target stats\n",
    "            mlflow.log_metric(\"target_mean\", y_train.mean())\n",
    "            mlflow.log_metric(\"target_std\", y_train.std())\n",
    "            \n",
    "            # Analyze feature types\n",
    "            feature_names = list(X_train_transformed.columns)\n",
    "            genre_count = len([f for f in feature_names if f.startswith('genre_')])\n",
    "            overview_count = len([f for f in feature_names if 'overview' in f])\n",
    "            title_count = len([f for f in feature_names if 'title' in f])\n",
    "            year_count = len([f for f in feature_names if 'year_bin' in f])\n",
    "            lang_count = len([f for f in feature_names if 'original_language' in f])\n",
    "            \n",
    "            mlflow.log_metric(\"genre_features\", genre_count)\n",
    "            mlflow.log_metric(\"overview_features\", overview_count)\n",
    "            mlflow.log_metric(\"title_features\", title_count)\n",
    "            mlflow.log_metric(\"year_features\", year_count)\n",
    "            mlflow.log_metric(\"language_features\", lang_count)\n",
    "            \n",
    "            print(f\"\\nFeature breakdown:\")\n",
    "            print(f\"  Genre: {genre_count}\")\n",
    "            print(f\"  Overview: {overview_count}\")\n",
    "            print(f\"  Title: {title_count}\")\n",
    "            print(f\"  Year: {year_count}\")\n",
    "            print(f\"  Language: {lang_count}\")\n",
    "            \n",
    "            # Save pipeline\n",
    "            pipeline_path = Path(f\"../models/feature_pipeline_{version_key}.pkl\")\n",
    "            pipeline_path.parent.mkdir(exist_ok=True)\n",
    "            \n",
    "            with open(pipeline_path, 'wb') as f:\n",
    "                pickle.dump(pipeline, f)\n",
    "            \n",
    "            # Log to MLflow\n",
    "            mlflow.sklearn.log_model(pipeline, f\"pipeline_{version_key}\")\n",
    "            \n",
    "            print(f\"\\n✓ Pipeline saved: {pipeline_path}\")\n",
    "            print(\"✓ MLflow logging complete\")\n",
    "            \n",
    "            return {\n",
    "                'version': version_key,\n",
    "                'name': config['name'],\n",
    "                'pipeline': pipeline,\n",
    "                'X_train': X_train_transformed,\n",
    "                'X_test': X_test_transformed,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "                'fit_time': fit_time,\n",
    "                'output_features': X_train_transformed.shape[1]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting pipeline: {e}\")\n",
    "            mlflow.log_param(\"status\", \"failed\")\n",
    "            mlflow.log_param(\"error\", str(e))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FITTING ALL PIPELINE VERSIONS\n",
      "======================================================================\n",
      "\n",
      "[1/2] Version 1: Original Pipeline\n",
      "\n",
      "======================================================================\n",
      "PIPELINE: Original (TF-IDF + OneHot)\n",
      "======================================================================\n",
      "Description: Baseline: TF-IDF text features with OneHotEncoder for categoricals\n",
      "\n",
      "MLflow tracking enabled\n",
      "Run ID: fb682cf813234c12b091db388fe49835\n",
      "\n",
      "Fitting pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/01 20:55:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/01 20:55:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline fitted in 0.87s\n",
      "Features: 8 → 119\n",
      "\n",
      "Transforming test data...\n",
      "Test data transformed in 0.07s\n",
      "\n",
      "Feature breakdown:\n",
      "  Genre: 19\n",
      "  Overview: 50\n",
      "  Title: 30\n",
      "  Year: 11\n",
      "  Language: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/01 20:55:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Pipeline saved: ../models/feature_pipeline_v1_original.pkl\n",
      "✓ MLflow logging complete\n",
      "\n",
      "[2/2] Version 2: Sentence Transformer Pipeline\n",
      "\n",
      "======================================================================\n",
      "PIPELINE: Sentence Transformers (Lambda-ready)\n",
      "======================================================================\n",
      "Description: Lightweight sentence embeddings (384 dim), suitable for Lambda deployment\n",
      "\n",
      "MLflow tracking enabled\n",
      "Run ID: c55bf2fb508b4f6eac6e593fc5c8289f\n",
      "\n",
      "Fitting pipeline...\n",
      "Pipeline fitted in 23.52s\n",
      "Features: 8 → 807\n",
      "\n",
      "Transforming test data...\n",
      "Test data transformed in 3.21s\n",
      "\n",
      "Feature breakdown:\n",
      "  Genre: 19\n",
      "  Overview: 384\n",
      "  Title: 384\n",
      "  Year: 11\n",
      "  Language: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/01 20:55:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/01 20:55:56 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/01 20:56:03 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Pipeline saved: ../models/feature_pipeline_v2_sentence_transformer.pkl\n",
      "✓ MLflow logging complete\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Successfully fitted 2/2 pipelines\n",
      "Pipeline Comparison:\n",
      "                Version                                 Name  Output Features Fit Time (s)\n",
      "            v1_original           Original (TF-IDF + OneHot)              119         0.87\n",
      "v2_sentence_transformer Sentence Transformers (Lambda-ready)              807        23.52\n"
     ]
    }
   ],
   "source": [
    "# Fit all pipeline versions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FITTING ALL PIPELINE VERSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Version 1: Original (always available)\n",
    "print(\"\\n[1/2] Version 1: Original Pipeline\")\n",
    "results['v1'] = fit_and_log_pipeline('v1_original', X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Version 2: Sentence Transformers (requires sentence-transformers)\n",
    "print(\"\\n[2/2] Version 2: Sentence Transformer Pipeline\")\n",
    "results['v2'] = fit_and_log_pipeline('v2_sentence_transformer', X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "successful = {k: v for k, v in results.items() if v is not None}\n",
    "print(f\"Successfully fitted {len(successful)}/{len(results)} pipelines\")\n",
    "\n",
    "if successful:\n",
    "    comparison_df = pd.DataFrame([{\n",
    "        'Version': v['version'],\n",
    "        'Name': v['name'],\n",
    "        'Output Features': v['output_features'],\n",
    "        'Fit Time (s)': f\"{v['fit_time']:.2f}\"\n",
    "    } for v in successful.values()])\n",
    "    \n",
    "    print(\"Pipeline Comparison:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No pipelines were successfully fitted\")\n",
    "\n",
    "# Store results for later use\n",
    "pipeline_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Transformed Data\n",
    "\n",
    "Save the transformed training and test data for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING TRANSFORMED DATA\n",
      "======================================================================\n",
      "\n",
      "✓ Saving Original (TF-IDF + OneHot) (v1)...\n",
      "\n",
      "✓ Saving Sentence Transformers (Lambda-ready) (v2)...\n",
      "\n",
      "======================================================================\n",
      "SAVED 2 pipeline versions\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save transformed data for each pipeline version\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING TRANSFORMED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "processed_data_dir = Path('../data/processed')\n",
    "processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for version_key, result in results.items():\n",
    "    if result is not None:\n",
    "        print(f\"\\n✓ Saving {result['name']} ({version_key})...\")\n",
    "        \n",
    "        # Get transformed data\n",
    "        X_train_transformed = result['X_train']\n",
    "        X_test_transformed = result['X_test']\n",
    "        y_train_data = result['y_train']\n",
    "        y_test_data = result['y_test']\n",
    "        \n",
    "        # Save to CSV files with version suffix\n",
    "        X_train_path = processed_data_dir / f'X_train_transformed_{version_key}.csv'\n",
    "        X_test_path = processed_data_dir / f'X_test_transformed_{version_key}.csv'\n",
    "        y_train_path = processed_data_dir / f'y_train_{version_key}.csv'\n",
    "        y_test_path = processed_data_dir / f'y_test_{version_key}.csv'\n",
    "        \n",
    "        X_train_transformed.to_csv(X_train_path, index=False)\n",
    "        X_test_transformed.to_csv(X_test_path, index=False)\n",
    "        y_train_data.to_csv(y_train_path, index=False, header=['vote_average'])\n",
    "        y_test_data.to_csv(y_test_path, index=False, header=['vote_average'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"SAVED {len([r for r in results.values() if r is not None])} pipeline versions\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
